{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MOBV7cjtEYum"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8KkPQeH-05_",
        "outputId": "b0913f1e-b441-4e33-f3a9-5543460c0c47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Establezco una ruta absoluta a un directorio existente de mi Google Drive\n",
        "BASE_FOLDER = \"/content/drive/Othercomputers/Mi portátil/Master/TFM/TFM/Datos\""
      ],
      "metadata": {
        "id": "e0k-cRM6_B0B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir =BASE_FOLDER +\"/Train\"\n",
        "test_dir = BASE_FOLDER +\"/Test\"\n",
        "val_dir = BASE_FOLDER +\"/Valid\""
      ],
      "metadata": {
        "id": "4yyITJbZBdx6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_matriz_3d_de_archivo(ruta_archivo, N):\n",
        "    \"\"\"\n",
        "    Carga una matriz 3D de tamaño N a partir de un archivo de texto que contiene\n",
        "    las coordenadas de los elementos que son 1. El resto de elementos serán 0.\n",
        "\n",
        "    :param ruta_archivo: str - Ruta al archivo de texto.\n",
        "    :param N: int - Tamaño de la matriz 3D (N x N x N).\n",
        "    :return: np.ndarray - Matriz 3D de tamaño N con valores 0 y 1.\n",
        "    \"\"\"\n",
        "    # Inicializar la matriz 3D con ceros\n",
        "    matriz_3d = np.zeros((N, N, N), dtype=int)\n",
        "\n",
        "    # Leer el archivo y procesar cada línea\n",
        "    with open(ruta_archivo, 'r') as archivo:\n",
        "        for linea in archivo:\n",
        "            # Separar las coordenadas (x, y, z)\n",
        "            x, y, z, _ = map(int, linea.strip().split(','))\n",
        "\n",
        "            # Asignar el valor 1 en la posición correspondiente\n",
        "            if 0 <= x < N and 0 <= y < N and 0 <= z < N:\n",
        "                matriz_3d[x, y, z] = 1\n",
        "\n",
        "    return matriz_3d"
      ],
      "metadata": {
        "id": "zv9TsrBs9ymx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_etiquetas_de_archivo(archivo, N):\n",
        "    \"\"\"\n",
        "    Carga las etiquetas de un archivo de texto en una matriz 3D de tamaño N.\n",
        "\n",
        "    \"\"\"\n",
        "    etiquetas = archivo.split('-')\n",
        "    matriz_etiqueta = np.zeros((N,N,N))\n",
        "    for i in range(3):\n",
        "        etiqueta=etiquetas[i]\n",
        "        if len(etiqueta)>0:\n",
        "            etiqueta=etiqueta.split('_')\n",
        "            etiqueta=list(map(int, etiqueta))\n",
        "            dim_x=etiqueta[0]\n",
        "            dim_y=etiqueta[1]\n",
        "            dim_z=etiqueta[2]\n",
        "            matriz_etiqueta[dim_x,dim_y,dim_z]=1\n",
        "    return matriz_etiqueta"
      ],
      "metadata": {
        "id": "E8cQF7ISDtk2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "# Listar archivos en la carpeta\n",
        "archivos = os.listdir(train_dir)\n",
        "\n",
        "# Filtrar solo archivos (no directorios)\n",
        "archivos = [archivo for archivo in archivos if os.path.isfile(os.path.join(train_dir, archivo))]\n",
        "# Dimension de la matriz 3d\n",
        "N = 30\n",
        "# Recorrer cada archivo en la carpeta\n",
        "for archivo in archivos:\n",
        "    #print(f\"Procesando archivo: {archivo}\")\n",
        "    y.append(cargar_etiquetas_de_archivo(archivo,N))\n",
        "    X.append(cargar_matriz_3d_de_archivo(os.path.join(train_dir, archivo), N))\n",
        "    #print(matriz_etiqueta)\n",
        "\n",
        "# Convertir X y y a arrays de numpy\n",
        "X = np.array(X)  # Shape (num_samples, 30, 30, 30)\n",
        "y = np.array(y)  # Shape (num_samples, 30, 30, 30)\n",
        "\n",
        "# Expandir la dimensión para el canal (necesario para Conv3D)\n",
        "X = np.expand_dims(X, axis=-1)  # Ahora tiene forma (num_samples, 30, 30, 30, 1)\n",
        "y = np.expand_dims(y, axis=-1)  # Ahora tiene forma (num_samples, 30, 30, 30, 1)"
      ],
      "metadata": {
        "id": "dFQ13yIWGM_K"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(X)"
      ],
      "metadata": {
        "id": "cLM0yroC_R4s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de pérdidas basada en la distancia entre los puntos reales y predichos\n",
        "def custom_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Función de pérdida personalizada para comparar nubes de puntos 3D,\n",
        "    optimizada para puntos con valor 1.\n",
        "\n",
        "    Args:\n",
        "        y_true: Tensor de etiquetas verdaderas, con forma (batch_size, 30*30*30).\n",
        "        y_pred: Tensor de predicciones, con forma (batch_size, 30*30*30).\n",
        "\n",
        "    Returns:\n",
        "        Pérdida calculada.\n",
        "    \"\"\"\n",
        "\n",
        "    # Reshape para obtener coordenadas individuales (x, y, z)\n",
        "    print('ok')\n",
        "    y_true = tf.reshape(y_true, (-1, 30, 30, 30, 3))\n",
        "    y_pred = tf.reshape(y_pred, (-1, 30, 30, 30, 3))\n",
        "    print('ytrue')\n",
        "    print(tf.shape(y_true))\n",
        "    print('ypred')\n",
        "    print(tf.shape(y_pred))\n",
        "\n",
        "    # Máscara para seleccionar solo los puntos con valor 1 en el canal Z\n",
        "    mask = tf.equal(y_true[..., 2], 1)\n",
        "    print(mask)\n",
        "    print('ok2')\n",
        "    # Aplicar la máscara a las coordenadas\n",
        "    points_true = tf.boolean_mask(y_true, mask)\n",
        "    points_pred = tf.boolean_mask(y_pred, mask)\n",
        "    print('ok3')\n",
        "    # Ordenar los puntos según las coordenadas x, y y z\n",
        "    def sort_points(points):\n",
        "        # Calculate indices for sorting based on all dimensions\n",
        "        indices = tf.argsort(points[:,0] + points[:,1] * 1000 + points[:,2] * 1000000)\n",
        "        # Gather points based on sorted indices\n",
        "        return tf.gather(points, indices, batch_dims=0)\n",
        "    print('ok4')\n",
        "    sorted_points_true = sort_points(points_true)\n",
        "    sorted_points_pred = sort_points(points_pred)\n",
        "    print('ok5')\n",
        "    # Calcular la distancia euclidiana entre puntos correspondientes\n",
        "    squared_difference = tf.square(sorted_points_true - sorted_points_pred)\n",
        "    squared_distance = tf.reduce_sum(squared_difference, axis=-1)\n",
        "    print('ok6')\n",
        "    distance = tf.sqrt(squared_distance)\n",
        "    print('ok7')\n",
        "    # Calcular la pérdida por distancia (por ejemplo, la media)\n",
        "    loss_distance = tf.reduce_mean(distance)\n",
        "    print(loss_distance)\n",
        "    return loss_distance\n",
        "\n"
      ],
      "metadata": {
        "id": "ZC8OU4UbB29r"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_loss(y_true, y_pred):\n",
        "    # Asumimos que y_true y y_pred son tensores de tamaño [batch_size, N, N, N]\n",
        "\n",
        "    # Encontrar los índices de los puntos de valor 1 en y_true y y_pred\n",
        "    true_indices = tf.where(tf.equal(y_true, 1))\n",
        "    pred_indices = tf.where(tf.equal(y_pred, 1))\n",
        "\n",
        "    # Definir la función de distancia euclidiana\n",
        "    def euclidean_dist(a, b):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(a - b), axis=-1))\n",
        "\n",
        "    # Dividir la matriz en 4 cuadrantes en el plano horizontal (primera y segunda dimensiones)\n",
        "    def divide_quadrants(indices, shape):\n",
        "        print(shape)\n",
        "        half_x = shape[0] // 2\n",
        "        half_y = shape[1] // 2\n",
        "        quadrants = []\n",
        "        quadrants.append(tf.boolean_mask(indices, (indices[:, 1] < half_x) & (indices[:, 2] < half_y))) # Cuadrante 1\n",
        "        quadrants.append(tf.boolean_mask(indices, (indices[:, 1] < half_x) & (indices[:, 2] >= half_y))) # Cuadrante 2\n",
        "        quadrants.append(tf.boolean_mask(indices, (indices[:, 1] >= half_x) & (indices[:, 2] < half_y))) # Cuadrante 3\n",
        "        quadrants.append(tf.boolean_mask(indices, (indices[:, 1] >= half_x) & (indices[:, 2] >= half_y))) # Cuadrante 4\n",
        "        return quadrants\n",
        "\n",
        "    # Obtener las dimensiones de las matrices\n",
        "    shape = tf.shape(y_true)\n",
        "\n",
        "    # Dividir los índices de puntos en cuadrantes para y_true y y_pred\n",
        "    true_quadrants = divide_quadrants(true_indices, shape)\n",
        "    pred_quadrants = divide_quadrants(pred_indices, shape)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for i in range(4):  # Comparar los puntos en cada cuadrante\n",
        "        if tf.size(true_quadrants[i]) > 0 and tf.size(pred_quadrants[i]) > 0:\n",
        "            # Extraer los primeros puntos para comparar (suponemos que hay un solo punto en cada cuadrante)\n",
        "            true_point = true_quadrants[i][0]\n",
        "            pred_point = pred_quadrants[i][0]\n",
        "            total_loss += euclidean_dist(true_point, pred_point)\n",
        "        else:\n",
        "            total_loss += 2 * N\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "HVPrcL8gkHqX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_loss_improved(y_true, y_pred, weights=None):\n",
        "    \"\"\"\n",
        "    Calcula la distancia promedio entre puntos 3D correspondientes en dos matrices,\n",
        "    dividiendo el espacio en octantes.\n",
        "\n",
        "    Args:\n",
        "        y_true: Tensor de verdad terrestre con forma [batch_size, N, N, N].\n",
        "        y_pred: Tensor de predicciones con forma [batch_size, N, N, N].\n",
        "        weights: Tensor opcional de pesos para cada octante, con forma [8].\n",
        "\n",
        "    Returns:\n",
        "        Tensor escalar representando la pérdida total.\n",
        "    \"\"\"\n",
        "\n",
        "     # Encontrar los índices de los puntos de valor 1 en y_true y y_pred\n",
        "    true_indices = tf.where(tf.equal(y_true, 1))\n",
        "    pred_indices = tf.where(tf.equal(y_pred, 1))\n",
        "\n",
        "    # Definir la función de distancia euclidiana\n",
        "    def euclidean_dist(a, b):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(a - b), axis=-1))\n",
        "\n",
        "     # Dividir la matriz en 4 cuadrantes en el plano horizontal (primera y segunda dimensiones)\n",
        "    def divide_quadrants(indices, shape):\n",
        "        print(shape)\n",
        "        half_x = shape[0] // 2\n",
        "        half_y = shape[1] // 2\n",
        "        quadrants = []\n",
        "        quadrants.append(tf.boolean_mask(indices, (indices[:, 1] < half_x) & (indices[:, 2] < half_y))) # Cuadrante 1\n",
        "        quadrants.append(tf.boolean_mask(indices, (indices[:, 1] < half_x) & (indices[:, 2] >= half_y))) # Cuadrante 2\n",
        "        quadrants.append(tf.boolean_mask(indices, (indices[:, 1] >= half_x) & (indices[:, 2] < half_y))) # Cuadrante 3\n",
        "        quadrants.append(tf.boolean_mask(indices, (indices[:, 1] >= half_x) & (indices[:, 2] >= half_y))) # Cuadrante 4\n",
        "        return quadrants\n",
        "\n",
        "    # Obtener las dimensiones de las matrices\n",
        "    shape = tf.shape(y_true)[1:]  # Ignorar el batch_size\n",
        "\n",
        "    # Dividir los índices de puntos en octantes para y_true y y_pred\n",
        "    true_octants = divide_quadrants(true_indices, shape)\n",
        "    pred_octants = divide_quadrants(pred_indices, shape)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for i in range(4):\n",
        "        if tf.size(true_octants[i]) > 0 and tf.size(pred_octants[i]) > 0:\n",
        "            # Calcular la distancia promedio entre todos los puntos del octante\n",
        "            distances = tf.map_fn(lambda x: euclidean_dist(x[0], x[1]),\n",
        "                                  (true_octants[i], pred_octants[i]),\n",
        "                                  dtype=tf.float32)\n",
        "            # Aplicar pesos si se proporcionan\n",
        "            if weights is not None:\n",
        "                distances *= weights[i]\n",
        "            total_loss += tf.reduce_mean(distances)\n",
        "        else:\n",
        "            total_loss += 2 * N\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "AQFIjCpWnrT_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELO v1\n",
        "\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definir el modelo de red convolucional 3D\n",
        "model = Sequential()\n",
        "\n",
        "# Capa convolucional 3D 1\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(N,N,N, 1)))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "# Capa convolucional 3D 2\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "# Capa convolucional 3D 3\n",
        "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "# Aplanar las características para pasarlas a la capa densa\n",
        "model.add(Flatten())\n",
        "\n",
        "# Capa densa completamente conectada\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Capa de salida para predecir el mapa de etiquetas (y)\n",
        "model.add(Dense(N*N*N, activation='sigmoid'))  # Redimensionar a una sola salida binaria por voxel\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss=custom_loss2, metrics=['accuracy'])\n",
        ""
      ],
      "metadata": {
        "id": "xuDMGXA9KX0V"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "2LB63upHRHZp",
        "outputId": "e463ea5f-633c-47d7-e147-b75a6796573d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv3d_30 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_30 (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_31 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m55,360\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_31 (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_32 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m221,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_32 (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m262,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27000\u001b[0m)               │       \u001b[38;5;34m6,939,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv3d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling3d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27000</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,939,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,478,968\u001b[0m (28.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,478,968</span> (28.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,478,968\u001b[0m (28.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,478,968</span> (28.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape de la salida y_train y y_test para que coincidan con la predicción\n",
        "y_train_reshaped = y_train.reshape(y_train.shape[0], -1)  # Cambiar forma a (num_samples, 30*30*30)\n",
        "y_test_reshaped = y_test.reshape(y_test.shape[0], -1)     # Cambiar forma a (num_samples, 30*30*30)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train_reshaped, epochs=5, batch_size=16, validation_data=(X_test, y_test_reshaped))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "wnjRpHiQrgjj",
        "outputId": "5a341f88-271d-485a-cb8a-0c30ad4722e1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "pred\n",
            "Tensor(\"compile_loss/custom_loss2/Equal_2:0\", shape=(), dtype=bool)\n",
            "true\n",
            "Tensor(\"compile_loss/custom_loss2/strided_slice:0\", shape=(), dtype=int32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OperatorNotAllowedInGraphError",
          "evalue": "Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-f7591eeb9fed>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Entrenar el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-76c24ea2051f>\u001b[0m in \u001b[0;36mcustom_loss2\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Si los puntos forman triángulos o rectángulos, calculamos las distancias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Suma de la distancia mínima de cada punto en true con los de pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdist_true_to_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mdist_pred_to_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-76c24ea2051f>\u001b[0m in \u001b[0;36mmin_distance\u001b[0;34m(points_true, points_pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdist_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpoint_true\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoints_true\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;31m# Calculamos las distancias de un punto verdadero a todos los puntos predichos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpoint_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.save( BASE_FOLDER +'/modelo2.keras')  # The file needs to end with the .keras extension\n"
      ],
      "metadata": {
        "id": "Clu-pR7LqxUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Pérdida: {loss}, Precisión: {accuracy}')"
      ],
      "metadata": {
        "id": "0-Q7YEN4Qy-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QsQ_p-2bSMm0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}